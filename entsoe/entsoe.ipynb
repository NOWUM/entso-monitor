{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTSO-E Daten\n",
    "\n",
    "Die Daten der European Network of Transmission System Operators for Electricity (ENTSO-E) werden auf dem Transparenzportal veröffentlicht.\n",
    "\n",
    "Über eine API lassen sich die Daten, sowie Historiendaten abfragen.\n",
    "\n",
    "Das Projekt unterteilt sich zunächst in 3 Teile:\n",
    "\n",
    "1. Daten abfragen und speichern\n",
    "2. Daten aufbereiten\n",
    "3. Daten visualisieren\n",
    "\n",
    "Referenzen:\n",
    "https://energy-charts.info/\n",
    "https://www.electricitymap.org/map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Begriffserklärungen / Glossar\n",
    "\n",
    "* **Generation** beschreibt das erzeugte, also den gesamten eingespeisten Strom, ohne absorbierter Energie\n",
    "* **Load/Last** beschreibt \"das Verbrauchte\", also das Erzeugte und Importierte minus absorbiertem und exportiertem.\n",
    "\n",
    "die aktuellen Werte werden i.d.R. über ein 15 Minuten Mittel erhalten. Manche Länder sende jedoch nur stündlich ihre Daten.\n",
    "Die Energie lässt sich dadurch durch Leistung * Zeit berechnen.\n",
    "\n",
    "Eine Umrechnung in kWh bedeutet also ein Teilen durch Faktor 4 der Summe (wenn Stunde die Gruppierung ist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten abfragen und speichern\n",
    "\n",
    "Die Daten stehen über eine API zur Verfügung. Hierzu benötigt man einen api_key, welchen man mit einer Mail-Adresse beantragen kann.\n",
    "Anschließend kann man anfragen an die API stellen. Hierzu benötigt man für jede Area den zugehörigen Code.\n",
    "Diese antwortet mit CSV bzw manchmal gezipptem CSV.\n",
    "\n",
    "Der Umgang hiermit wird erheblich durch eine bestehende Python-Bibliothek erleichtert.\n",
    "\n",
    "Mit der entsoe-py Bibliothek können wir die Daten direkt als Pandas-DataFrame runterladen.\n",
    "Diese stellt die folgenden Endpunkte bereit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from entsoe import EntsoePandasClient\n",
    "import matplotlib.pyplot as plt\n",
    "client = EntsoePandasClient(api_key='ae2ed060-c25c-4eea-8ae4-007712f95375')\n",
    "\n",
    "object_methods = [method_name for method_name in dir(client)\n",
    "                  if callable(getattr(client, method_name))]\n",
    "# only public ones\n",
    "list(filter(lambda k: not str.startswith(k,'_'), object_methods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wir beschränken uns hierbei auf:\n",
    "* die Auslastung: `query_load`,\n",
    "* die generierte Energie: `query_generation`,\n",
    "* die generierte Energie pro Kraftwerk: `query_generation_per_plant`\n",
    "* die vorhandenen Kapazitäten: `query_installed_generation_capacity`\n",
    "* diese gibt es auch noch pro Kraftwerk: `query_installed_generation_capacity_per_unit`\n",
    "* außerdem gibt es noch die Übertragungsdaten zwischen den Ländern: `query_crossborder_flows`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Beginn der Datenaufzeichnungen im neuen Format der ENTSO-E ist der 1.1.2015 für Deutschland. Andere Länder haben erst später mit den Aufzeichnungen angefangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# german data available since\n",
    "begin = pd.Timestamp('20150101', tz='Europe/Berlin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns mal die Auslastung der letzten 5 Tage an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "from entsoe.mappings import PSRTYPE_MAPPINGS,NEIGHBOURS,Area\n",
    "areas = pd.DataFrame([[e.name,e.value,e._tz,e._meaning] for e in Area])\n",
    "load = pd.DataFrame()\n",
    "country_code = 'DE'\n",
    "\n",
    "today=datetime.strftime(datetime.now().date(),'%Y%m%d')\n",
    "prev5=datetime.now().date()-timedelta(days=5)\n",
    "prev5str=datetime.strftime(prev5,'%Y%m%d')\n",
    "\n",
    "start = pd.Timestamp(prev5str, tz='Europe/Berlin')\n",
    "end = pd.Timestamp(today, tz='Europe/Berlin')\n",
    "\n",
    "load[country_code] = client.query_load(country_code, start=start,end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(load['DE'])\n",
    "\n",
    "import plotly.express as px \n",
    "fig = px.line(df, x=df.index, y='DE')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu beachten ist hierbei, dass die Daten zum einen pro Land erfasst werden, zum anderen auch pro BiddingZone, also pro Marktgebiet.\n",
    "So gibt es ebenfalls Daten für DE, DE_LU, DE_AT_LU, DE_50HERTZ, DE_AMPRION.\n",
    "\n",
    "Die Unterscheidung muss für alle Datenwerte beachtet werden, was visualisiert werden soll.\n",
    "\n",
    "Intern gibt es für diese Bereiche noch eine nicht lesbare ID. Die Übersetzung in die Marktgebiete wie sie auf der Webseite zu finden sind, erfolgt bereits in dem Python-Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print (e.name) for e in Area] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karte der Kraftwerke\n",
    "\n",
    "Die Kraftwerke eines Marktgebietes kann man sich über die API runterladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod = client.query_installed_generation_capacity_per_unit('DE_AT_LU',start=start,end=end)\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('BE',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('DE_AMPRION',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('DE_50HZ',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('DE_LU',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('FR',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('CH',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('AT',start=start,end=end)])\n",
    "prod = pd.concat([prod,client.query_installed_generation_capacity_per_unit('GB',start=start,end=end)])\n",
    "prod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allerdings sind hier keine Koordinaten enthalten. Die Koordinaten für \"Konventionelle Kraftwerke\" werden glücklicherweise von einer externen Webseite bereitgestellt:\n",
    "\n",
    "Leider konnte ich keine Quelle finden, welche die Werte frei verfügbar nach EIC_CODE aufgeschlüsselt für Solar und Wind ebenfalls enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://data.open-power-system-data.org/conventional_power_plants/latest/conventional_power_plants_EU.csv')\n",
    "# uns interessieren nur Daten, welche auch Koordinaten und einen Key enthalten\n",
    "df.dropna(axis=0,subset=['lon','lat','eic_code'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir durch einen join der Datasets eine Karte von Kraftwerken erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['eic_code']\n",
    "joined = prod.join(df)[['Name','lon','lat','capacity','Production Type','country']]\n",
    "joined.dropna(axis=0,subset=['lon','lat'],inplace=True)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_mapbox(joined, lat=\"lat\", lon=\"lon\", color='country',hover_name=\"Name\",hover_data=[\"capacity\",'Production Type'],zoom=3)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\",margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Karte kann man nach Ländern filtern und sich einzelne Punkte oder Länder ansehen.\n",
    "\n",
    "Alternativ kann man die Karte farblich statt nach Ländern auch nach Kraftwerktyp visualisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_mapbox(joined, lat=\"lat\", lon=\"lon\", color='Production Type',hover_name=\"Name\",hover_data=[\"capacity\",'Production Type'],zoom=3)\n",
    "fig.update_layout(mapbox_style=\"carto-positron\",margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas containing load content\n",
    "valid_areas=[]\n",
    "for e in Area:\n",
    "    country_code = e.name\n",
    "    try:\n",
    "        load[country_code] = client.query_load(country_code, start=start,end=end)\n",
    "        valid_areas.append(country_code)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        #print('failed:',country_code, e)\n",
    "        \n",
    "valid_countries = list(filter(lambda x: len(x)<=2,valid_areas))\n",
    "\"['\"+\"','\".join(valid_countries)+\"']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "data= []\n",
    "valid_countries=['DE','BE','NL','FR','CZ','PL','NO','IT','ES']\n",
    "#for country_code in valid_countries:\n",
    "for country_code in ['DE','BE','NL','FR','CZ','PL','NO','IT','ES']:\n",
    "    load[country_code]=client.query_load(country_code, start=start,end=end)\n",
    "    data.append(go.Scatter(x=load.index,y=load[country_code]/1000,name=country_code,   \n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(26,0,65,0.1)',\n",
    "        #stackgroup='one',\n",
    "        #stackgaps='interpolate'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets\n",
    "\n",
    "textbox = widgets.Dropdown(\n",
    "    description='Länder:   ',\n",
    "    value=valid_countries[0],\n",
    "    options=valid_countries,\n",
    "    multiselect=True,\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(data=data)\n",
    "fig.update_layout(\n",
    "    title=\"Netzlast der Länder\",\n",
    "    xaxis_title=\"Zeit\",\n",
    "    yaxis_title=\"Leistung in MW\",\n",
    "    legend_title=\"Länder\",\n",
    "    font=dict(\n",
    "        #family=\"Courier New, monospace\",\n",
    "        #size=18,\n",
    "        #color=\"RebeccaPurple\"\n",
    "    ),)\n",
    "\n",
    "import time\n",
    "def response(change):\n",
    "    with fig.batch_update():\n",
    "        fig.data = []\n",
    "        fig.add_trace(go.Scatter(x=load.index,y=load[textbox.value]/1000,name=textbox.value,\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(26,0,65,0.1)',\n",
    "            #stackgroup='one',\n",
    "            #stackgaps='interpolate'\n",
    "            ))\n",
    "        fig.update_layout(showlegend=True)\n",
    "textbox.observe(response, names=\"value\")\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "widgets.VBox([widgets.HBox([textbox]),\n",
    "              fig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verläufe sind in ihrer Bewegung der Netzauslastung sehr ähnlich. Je größer das Land, desto größer sind auch die Schwankungen.\n",
    "\n",
    "Wenn man sich die Daten anguckt, sieht man, dass nicht alle Daten viertelstündlich, wie DE vorliegen. Spanien (ES) melde die Daten nur stündlich. Das muss bei der Speicherung beachtet werden.\n",
    "\n",
    "Betrachten wir noch die Kapazitäten der Länder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kapazität der Länder nach Jahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "capacity = {}\n",
    "start1 = pd.Timestamp('20150101', tz='Europe/Berlin')\n",
    "end1 = pd.Timestamp('20200102', tz='Europe/Berlin')\n",
    "\n",
    "for country_code in valid_countries:\n",
    "    capacity[country_code] = client.query_installed_generation_capacity(country_code, start=start1,end=end1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "country_code =list(capacity.keys())[0]\n",
    "\n",
    "textbox = widgets.Dropdown(\n",
    "    description='Länder:   ',\n",
    "    value=country_code,\n",
    "    options=list(capacity.keys()),\n",
    ")\n",
    "data= []\n",
    "curDat = capacity[country_code]\n",
    "for fuel in list(curDat.keys()):\n",
    "        data.append(go.Scatter(x=curDat.index,y=curDat[fuel]/1000,name=fuel,   \n",
    "    #fill='tozeroy',\n",
    "    stackgroup='one',\n",
    "    stackgaps='interpolate'\n",
    "    ))\n",
    "\n",
    "fig = go.FigureWidget(data=data)\n",
    "fig.update_layout(\n",
    "    title=\"Erzeugungskapazitäten der Länder, unterteilt nach Sorte\",\n",
    "    xaxis_title=\"Jahr\",\n",
    "    yaxis_title=\"Erzeugungskapazität in MW\",\n",
    "    legend_title=\"Sorten\",\n",
    "    font=dict(\n",
    "        #family=\"Courier New, monospace\",\n",
    "        #size=18,\n",
    "        #color=\"RebeccaPurple\"\n",
    "    ),)\n",
    "\n",
    "def response(change):\n",
    "    with fig.batch_update():\n",
    "        fig.data = []\n",
    "        curDat = capacity[textbox.value]\n",
    "        for fuel in list(curDat.keys()):\n",
    "            fig.add_trace(go.Scatter(x=curDat.index,y=curDat[fuel]/1000,name=fuel,   \n",
    "                #fill='tozeroy',\n",
    "                stackgroup='one',\n",
    "                stackgaps='interpolate'\n",
    "                ))\n",
    "        fig.update_layout(showlegend=True)\n",
    "textbox.observe(response, names=\"value\")\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "widgets.VBox([widgets.HBox([textbox]),\n",
    "              fig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier hat man leider auch nicht immer die selben verfügbaren Werte. Zur Speicherung in einer Datenbank muss man also das Schema dynamisch aufbauen oder vorher alle jemals verfügbaren Erzeugnisformen kennen.\n",
    "\n",
    "Später möchte man in einer Visualisierung den einzelnen Erzeugnissen auch immer die selbe Farbe geben (Solar=gelb,Kohle=Schwarz usw), weshalb man auch hier mit fehlenden oder hinzukommenden Werten klar kommen muss.  \n",
    "\n",
    "Holprig wird es erst bei den Stromerzeugungs-Daten:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stromerzeugung in Deutschland in aktueller Woche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceStr(string):\n",
    "    '''\n",
    "    Apache Spark gefallen einige Zeichen der Columns nicht.\n",
    "    Diese werden hier ersetzt\n",
    "    '''\n",
    "    \n",
    "    st = str.replace(string,')','')\n",
    "    st = str.replace(st,'(','')\n",
    "    st = str.replace(st,',','')\n",
    "    st = str.replace(st,\"'\",'')\n",
    "    st = st.strip()\n",
    "    st = str.replace(st,' ','_')\n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst holen wir uns die Daten über die API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen=pd.DataFrame() # does not work with differing columns\n",
    "gen={}\n",
    "country='GR'\n",
    "gen[country] = client.query_generation(country, start=start,end=end) # no data for DE\n",
    "gen[country]['time']=gen[country].index\n",
    "country='DE'\n",
    "gen[country] = client.query_generation(country, start=start,end=end) # no data for DE\n",
    "gen[country]['time']=gen[country].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen['DE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen['GR'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sieht also, dass die Daten unterschiedliche Strukturen haben. Nicht immer erfolgt die Aufschlüsselung nach Erzeugnissen (Actual Aggregated) und der zur Erzeugung benötigten Energie (actual Consumption)\n",
    "\n",
    "Hierzu müssen die Daten über die Differenzen gebildet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert multiindex to single index\n",
    "gen['DE'].columns = list(map(replaceStr, map(str,gen['DE'].columns)))\n",
    "# unpivot data for visualization\n",
    "g = gen['DE'].melt(id_vars=['time'],  var_name='kind', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "fig = px.line(g, x='time', y='value', color='kind',title='Stromerzeugnis in Deutschland der letzten 5 Tage in kWh')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Grafik kann man mit einem Doppelklick auf \"Hydro Pumped Storage Actual Aggregated\" und anschließendem einfach Klick \"Hydro Pumped Storage Actual Consumption\" sich zwei Series zusammen angucken.\n",
    "\n",
    "Hier sieht man, dass der Pumpwasserspeicher tagsüber Strom erhält und nachts Strom in das Netz einspeist.\n",
    "\n",
    "\n",
    "Für Griechenland erhält man diese Daten nicht aufgeschlüsselt, weshalb hier nur der eingespeiste Wert verfügbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert multiindex to single index\n",
    "gen['GR'].columns = list(map(replaceStr, map(str,gen['GR'].columns)))\n",
    "# unpivot data for visualization\n",
    "g = gen['GR'].melt(id_vars=['time'],  var_name='kind', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "fig = px.line(g, x='time', y='value', color='kind')\n",
    "fig.update_layout(\n",
    "    title='Stromerzeugnis in Griechenland der letzten 5 Tage in kWh',\n",
    "    xaxis_title=\"Datum\",\n",
    "    yaxis_title=\"Erzeugnis in kWh\",\n",
    "    legend_title=\"Erzeugungsform\",    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit man diese Daten nun unter einen Hut bekommt, muss man nun jeweils die Differenz zwischen Consumption und Aggregation erhalten und den MultiIndex gegebenenfalls umbenennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDiff(data, inplace=False):\n",
    "    '''\n",
    "    Berechnet jeweils Differenzen zwischen den zugehörigen zwei Spalten.\n",
    "    '''\n",
    "    if not inplace:\n",
    "        dat = data.copy()\n",
    "    else:\n",
    "        dat=data\n",
    "    for c in filter(lambda x:x.endswith('_Actual_Aggregated'), dat.columns):        \n",
    "        new = str.replace(c,'_Actual_Aggregated','')\n",
    "        dif = list(filter(lambda x: x.endswith('_Actual_Consumption') and x.startswith(new), dat.columns ))\n",
    "        if len(dif) > 0:\n",
    "            # wenn es beides gibt wird die Differenz gebildet\n",
    "            print(dif[0])\n",
    "            dat[new]=dat[c]-dat[dif[0]]\n",
    "            del dat[c]\n",
    "            del dat[dif[0]]\n",
    "        else:\n",
    "            # sonst wird direkt \n",
    "            dat[new]=dat[c]\n",
    "            del dat[c]\n",
    "    for c in filter(lambda x:x.endswith('_Actual_Consumption'), dat.columns):\n",
    "        # wenn es nur Verbrauch aber kein Erzeugnis gibt, mach negativ\n",
    "        new = str.replace(c,'_Actual_Consumption','')\n",
    "        dat[new]=-dat[c]\n",
    "        del dat[c]\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gen['DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = list(map(replaceStr, map(str,data.columns)))\n",
    "data.fillna(0, inplace=True)\n",
    "# calculate difference betweeen agg and consumption\n",
    "data=calcDiff(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir einheitliche Namen der Erzeugnisformen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deutschland erhalten wir nun die Netto Erzeugnisse. Das erzeugt für den Pumpspeicher negative Werte, was die Interpretation auch erleichtert.\n",
    "\n",
    "Im Area-Plot ist die Visualisierung trotzdem korrekt und stellt die Erzeugung nach Erzeugungsform dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.melt(id_vars=['time'],  var_name='kind', value_name='value')\n",
    "fig = px.area(g, x='time', y='value', color='kind')\n",
    "fig.update_layout(\n",
    "    title='Stromerzeugnis in Deutschland der letzten 5 Tage in kWh',\n",
    "    xaxis_title=\"Datum\",\n",
    "    hovermode=\"closest\",\n",
    "    yaxis_title=\"Erzeugnis in kWh\",\n",
    "    legend_title=\"Erzeugungsform\",    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswahl des Landes über eine Chloropleth Karte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Auswahl eines Landes soll durch Anklicken des Gebietes ermöglicht werden.\n",
    "Eine mögliche Visualisierung ist auch, eine Zeit auszuwählen, zu der die Karten nach aktuellem Load visualisiert werden.\n",
    "Das ist allerdings nur begrenzt sinnvoll, wenn man die Gebietsgröße nicht mit einbezieht.\n",
    "\n",
    "Alternativ könnte man den Wert relativ zur Maximallast betrachten.\n",
    "Das sei hier aber nur erwähnt und wurde aufgrund des Aufwands nicht durchgeführt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "countries = ['DE','FR','GR','PL','LU','IT']\n",
    "\n",
    "with open(\"europe.geo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    geo = json.load(f)    \n",
    "\n",
    "#geo['features'][0]\n",
    "df = pd.DataFrame()\n",
    "df['countries']=countries\n",
    "df['values']=list(map(lambda x: ord(x[0]),countries))\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(df, geojson=geo, locations=\"countries\", color='values',\n",
    "                           color_continuous_scale=\"Jet\",\n",
    "                           featureidkey=\"properties.iso_a2\",\n",
    "                           range_color=(65, 80),\n",
    "                           mapbox_style=\"carto-positron\", # open-street-map\n",
    "                           zoom=3, center = {\"lat\": 50.0902, \"lon\": 10.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'values':'Werte'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie hat sich die Stromförderung durch Corona verändert?\n",
    "\n",
    "Problematik: Daten liegen nur viertelstündlich vor. Zum sinnvollen Gruppieren (nach Monat) wird eine Datenspeicherung benötigt und Zugriff auf die Historiendaten.\n",
    "\n",
    "Es ist möglich die Daten in Parquet zu speichern.\n",
    "Ein andere sinnvolle Möglichkeit erscheint SQLite zu sein, da man es recht leicht ansprechen kann und dank in-memory-Datenbanken auch ordentlich Performance in einem nicht-verteilten System erhält.\n",
    "Da lediglich viertelstündlich Daten gespeichert werden und die Datenmenge ungefähr 60 Länder * ~ 16 Spalten + 60 Länder * ~50 Kraftwerke also ganz grob 3600 Werte enthält, welche in einem relationalen Format gespeichert werden, kommt man hier mit konventionellen RDBMS gut davon.\n",
    "\n",
    "Spannend wären bspw Abweichungen von den Vormonaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speicherung der Daten\n",
    "\n",
    "Zur Speicherung der Daten müssen diese Paket-weise von der API runtergeladen werden und in einem sinnvollen Format abgespeichert werden.\n",
    "\n",
    "Nach einem ersten Ansatz, welcher pro Land eine eigene Tabelle vorsah, wurde nun das folgende Datenbank-Schema gewählt:\n",
    "\n",
    "![ER-Diagramm](diagrams-ENTSO-E.png)\n",
    "\n",
    "Hier gibt es nur noch für die Erzeugungen nach Kraftwerk eine eigene Tabelle pro Land.\n",
    "Wobei diese vermutlich auch sinnvoller als unpivot Tabelle behandelt werden sollte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Herunterladen der Daten wurde eine Klasse angelegt, welche die Paketierung übernimmt und sowohl die Speicherung in eine SQLite-Tabelle übernimmt, wie auch in Parquet übernimmt.\n",
    "\n",
    "Hierbei wurde viel mit der Speicherung der Datumswerte und einer Partitionierung der Parquet-Dateien experimentiert, welche Performance-technisch auf dem Programmier-Laptop nichts änderten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Speicherung der Zeitwerte läuft nativ schon sehr gut, durch ein Abspeichern des TimeStamps.\n",
    "\n",
    "Der TimeStamp lässt sich in SQLite zur Gruppierung mit der SQLite-Funktion strftime manipulieren.\n",
    "Durch `strftime(\"%Y-%m-%d %H:00:00\", \"index\") as time` erhält man den zur Stunde abgeschnittenen Wert.\n",
    "Mit `strftime(\"%Y-%m-%d\", \"index\") as time` respektive den Wert für ein Zusammenfassen nach Tagen\n",
    "\n",
    "Eine Gruppierung nach `time` und aggregation mit sum bzw avg bringt die gewünschten Ergebnisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Apache Spark und Parquet läuft das ziemlich analog.\n",
    "\n",
    "Den TimeStamp kann man sich über die spark.sql.function date_trunc abschneiden lassen. Hier kann man direkt sagen, wo abgeschnitten werden soll: `spark_df.withColumn(\"time\", date_trunc('day',\"time\"))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARK\n",
    "\n",
    "Der Einfachheithalber wurden die Daten bereits herunter geladen und mithilfe von Parquet abgespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "conf = SparkConf().setAppName('entsoe').setMaster('local')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDE = spark.read.parquet('data/DE/query_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg=loadDE.select('time').rdd.min()\n",
    "end=loadDE.select('time').rdd.max()\n",
    "\n",
    "print('Datensequenz von {} bis {}'.format(beg[0],end[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_trunc\n",
    "groupTime='month'\n",
    "\n",
    "loadBE = spark.read.parquet('data/BE/query_load').withColumn(groupTime, date_trunc(groupTime,\"time\"))\n",
    "floadBE = spark.read.parquet('data/BE/query_load_forecast').withColumn(groupTime, date_trunc(groupTime,\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pl=loadBE.groupby(groupTime).avg('0').toPandas()\n",
    "%time pf=floadBE.groupby(groupTime).avg('0').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "pl.sort_values(groupTime,inplace=True)\n",
    "pf.sort_values(groupTime,inplace=True)\n",
    "pf['forecast']=pf['avg(0)']\n",
    "pf['actual']=pl['avg(0)']\n",
    "fig = px.line(pf, x=groupTime, y=['actual','forecast'], title='Auslastung Belgien')\n",
    "fig.update_layout( xaxis_title='Datum',\n",
    "                   yaxis_title='Durchsatz in kW gemittelt pro Stunde')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich das ganze auch in SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "from contextlib import closing\n",
    "country = 'BE'\n",
    "selectString='strftime(\"%Y-%m-01\", \"index\") as time, avg(\"0\") as value'\n",
    "groupString='strftime(\"%Y-%m-01\", \"time\")'\n",
    "with closing(sql.connect('data/entsoe2.db')) as conn:\n",
    "    query = f\"select {selectString} from {country}_query_load group by {groupString}\"\n",
    "    %time load = pd.read_sql_query(query,conn,index_col='time')\n",
    "    query = f\"select {selectString} from {country}_query_load_forecast group by {groupString}\"\n",
    "    %time forecast = pd.read_sql_query(query,conn,index_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load['forecast']=forecast['value']\n",
    "\n",
    "fig = px.line(load, x=load.index, y=['value','forecast'], title='Auslastung Belgien')\n",
    "fig.update_layout( xaxis_title='Datum',\n",
    "                   yaxis_title='Durchsatz in kW gemittelt pro Stunde')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluss zu benachbarten Ländern\n",
    "\n",
    "\n",
    "* Karte mit Änderungsflüssen\n",
    "* wunderschön wäre eine Animation über die Zeit, mit Darstellung der Förderung durch Farben\n",
    "\n",
    "Es kann festgestellt werden wie der Fluss zu benachbarten Ländern ist.\n",
    "\n",
    "Hierzu kann beim Anklicken eines Landes der Netto-Transfer (Exportiert-importiert) berechnet werden.\n",
    "Die Daten müssen hierzu in ein geeignetes Format gebracht werden (neighbours Tabelle an crossboarders joinen..)\n",
    "Eigentlich müsste an jede Beziehung der Neighbours-Tabelle eine Series gejoined werden ->\n",
    "    realisieren durch crossboarder-Tabelle, welche alle nachbarschaftsbeziehungen als Key enthält"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBuilder(n):\n",
    "    res =''\n",
    "    for x in n:\n",
    "        fr =x.split('.')[0]\n",
    "        to =x.split('.')[1]\n",
    "        # export - import\n",
    "        res += f'sum(\"{fr}.{to}\"-\"{to}.{fr}\") as diff_{to}'\n",
    "        res += ','\n",
    "    return res\n",
    "        \n",
    "def neighbours(fr):\n",
    "    nei=[]\n",
    "    for x in columns:\n",
    "        sp = x.split('.')\n",
    "        if sp[0]==fr:\n",
    "            nei.append(x)  \n",
    "            #nei.append(sp[1]+'.'+sp[0])\n",
    "    return nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'ES'\n",
    "\n",
    "with closing(sql.connect('data/entsoe2.db')) as conn:\n",
    "    query = 'select * from query_crossborder_flows where 0=1'\n",
    "    columns= pd.read_sql_query(query,conn).columns\n",
    "    nei = neighbours(country)\n",
    "    n = selectBuilder(nei)\n",
    "    selectString='strftime(\"%Y-%m-%d %H:00:00\", \"index\") as time,'\n",
    "    groupString='strftime(\"%Y-%m-%d  %H:00:00\", \"index\")'\n",
    "    query = f'select {selectString}{n} \"index\" from query_crossborder_flows group by {groupString}'\n",
    "    neigh = pd.read_sql(query,conn,index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.line(neigh, x=neigh.index, y=['diff_FR','diff_PT'], title='Netto Export an Nachbarn von Spanien')\n",
    "fig.update_layout( xaxis_title='Datum',\n",
    "                   yaxis_title='Export - Import an Nachbarn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu erkennen ist, dass Spanien von Portugal importiert und mehr nach Frankreich exportiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey-Diagramm über Gesamt-Generierte Daten und Flüsse zwischen den Ländern\n",
    "\n",
    "Über die Jahre kann man dann eine Art Zustandsdiagramm machen, welcher Staat wie autark ist und wer stets Strom zugeführt bekommen muss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie gut ist die Vorhersage der erzeugten Daten? Können wir etwas besseres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTSO-E schreibt:\n",
    "> The day-ahead forecast is calculated (estimated) on the historic load profile on similar days, taking into account the variables that affect electricity demand, such as weather conditions, climate and socioeconomic factors.\n",
    "\n",
    "Vielleicht lässt sich mit Machine-Learning ein besseres Modell finden.\n",
    "\n",
    "Problematik: zyklische Trainingsdaten, weniger Daten (Wetter, Klima und Sozioökonomische Daten fehlen)\n",
    "\n",
    "Abweichung der Schätzungen vergleichen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
